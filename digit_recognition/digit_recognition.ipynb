{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n",
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# First, we load all the data from the NotMNIST dataset\n",
    "# -------------------------------------------------\n",
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "    \n",
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)\n",
    "  \n",
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)\n",
    "# -------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQiSKFr8QifJ/aZ+DL9tEwgcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dbae990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# Let's define some helpful functions\n",
    "# -------------------------------------------------\n",
    "    \n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def oneHot(num, length):\n",
    "    arr = np.zeros(length)\n",
    "    arr[num-1]=1.0\n",
    "    return arr\n",
    "\n",
    "newSize=32\n",
    "imgSize=54\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Then, let's define the functions for returning scale, crop and rotation variants for each image\n",
    "# -------------------------------------------------\n",
    "# input is x by y array\n",
    "def rotate(pixels, newSize, angle):\n",
    "    size = pixels.shape[0]\n",
    "    newPixels = np.full([newSize, newSize], -0.5)\n",
    "    startPos = (newSize-size)//2\n",
    "    for i in range(0,size):\n",
    "        for j in range(0,size):\n",
    "            newPixels[startPos+i][startPos+j] = pixels[i][j]\n",
    "    newPixels = newPixels + 0.5\n",
    "    cols = newSize\n",
    "    rows = newSize\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle, 1)\n",
    "    rotated = cv2.warpAffine(newPixels,M,(cols,rows))\n",
    "    rotated = rotated - 0.5\n",
    "    return rotated        \n",
    "\n",
    "def translate(image, widthTranslate, heightTranslate):\n",
    "    newPixels = image+0.5\n",
    "    M = np.float32([[1,0,widthTranslate],[0,1,heightTranslate]])\n",
    "    newPixels = cv2.warpAffine(newPixels,M,(image.shape[1],image.shape[0]))\n",
    "    return newPixels-0.5\n",
    "\n",
    "def getVariant(digits, toSize):\n",
    "    angles = [330, 345,0,15,30]\n",
    "    angle = random.choice(angles)\n",
    "    numberOfDigits = digits.shape[0]\n",
    "    variant=np.full([newSize, newSize*numberOfDigits], -0.5) \n",
    "    for num, digit in enumerate(digits):\n",
    "        digit=rotate(digit, newSize, angle)\n",
    "        for i in range(0,newSize):\n",
    "            for j in range(0,newSize):\n",
    "                if(digit[i][j]>-0.5):\n",
    "                    variant[i][(num*newSize)+j] = digit[i][j]    \n",
    "    #variant = translate(variant, random.randint(-5,5), random.randint(-5,5))\n",
    "    variant = cv2.resize(variant, (toSize, toSize)) \n",
    "    return variant\n",
    "\n",
    "import random\n",
    "    \n",
    "#We make the function to get some variants of the image & test it\n",
    "sampleImage1=train_dataset[random.randint(0,train_dataset.shape[0])]\n",
    "sampleImage1=np.reshape(sampleImage1, [28, 28])\n",
    "sampleImage2=train_dataset[random.randint(0,train_dataset.shape[0])]\n",
    "sampleImage2=np.reshape(sampleImage2, [28, 28])\n",
    "sampleImage3=train_dataset[random.randint(0,train_dataset.shape[0])]\n",
    "sampleImage3=np.reshape(sampleImage3, [28, 28])\n",
    "\n",
    "digits = np.ndarray([3,28,28])\n",
    "digits[0] = np.copy(sampleImage1)\n",
    "digits[1] = np.copy(sampleImage2)\n",
    "digits[2] = np.copy(sampleImage3)\n",
    "variant = getVariant(digits, imgSize)\n",
    "plt.imshow(variant, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "for i in range(0,5):\n",
    "    print(oneHot(i+1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Train data from about 2000 digits\n",
      "Completed 0 of 50000\n",
      "Completed 500 of 50000\n",
      "Completed 1000 of 50000\n",
      "Completed 1500 of 50000\n",
      "Completed 2000 of 50000\n",
      "Completed 2500 of 50000\n",
      "Completed 3000 of 50000\n",
      "Completed 3500 of 50000\n",
      "Completed 4000 of 50000\n",
      "Completed 4500 of 50000\n",
      "Completed 5000 of 50000\n",
      "Completed 5500 of 50000\n",
      "Completed 6000 of 50000\n",
      "Completed 6500 of 50000\n",
      "Completed 7000 of 50000\n",
      "Completed 7500 of 50000\n",
      "Completed 8000 of 50000\n",
      "Completed 8500 of 50000\n",
      "Completed 9000 of 50000\n",
      "Completed 9500 of 50000\n",
      "Completed 10000 of 50000\n",
      "Completed 10500 of 50000\n",
      "Completed 11000 of 50000\n",
      "Completed 11500 of 50000\n",
      "Completed 12000 of 50000\n",
      "Completed 12500 of 50000\n",
      "Completed 13000 of 50000\n",
      "Completed 13500 of 50000\n",
      "Completed 14000 of 50000\n",
      "Completed 14500 of 50000\n",
      "Completed 15000 of 50000\n",
      "Completed 15500 of 50000\n",
      "Completed 16000 of 50000\n",
      "Completed 16500 of 50000\n",
      "Completed 17000 of 50000\n",
      "Completed 17500 of 50000\n",
      "Completed 18000 of 50000\n",
      "Completed 18500 of 50000\n",
      "Completed 19000 of 50000\n",
      "Completed 19500 of 50000\n",
      "Completed 20000 of 50000\n",
      "Completed 20500 of 50000\n",
      "Completed 21000 of 50000\n",
      "Completed 21500 of 50000\n",
      "Completed 22000 of 50000\n",
      "Completed 22500 of 50000\n",
      "Completed 23000 of 50000\n",
      "Completed 23500 of 50000\n",
      "Completed 24000 of 50000\n",
      "Completed 24500 of 50000\n",
      "Completed 25000 of 50000\n",
      "Completed 25500 of 50000\n",
      "Completed 26000 of 50000\n",
      "Completed 26500 of 50000\n",
      "Completed 27000 of 50000\n",
      "Completed 27500 of 50000\n",
      "Completed 28000 of 50000\n",
      "Completed 28500 of 50000\n",
      "Completed 29000 of 50000\n",
      "Completed 29500 of 50000\n",
      "Completed 30000 of 50000\n",
      "Completed 30500 of 50000\n",
      "Completed 31000 of 50000\n",
      "Completed 31500 of 50000\n",
      "Completed 32000 of 50000\n",
      "Completed 32500 of 50000\n",
      "Completed 33000 of 50000\n",
      "Completed 33500 of 50000\n",
      "Completed 34000 of 50000\n",
      "Completed 34500 of 50000\n",
      "Completed 35000 of 50000\n",
      "Completed 35500 of 50000\n",
      "Completed 36000 of 50000\n",
      "Completed 36500 of 50000\n",
      "Completed 37000 of 50000\n",
      "Completed 37500 of 50000\n",
      "Completed 38000 of 50000\n",
      "Completed 38500 of 50000\n",
      "Completed 39000 of 50000\n",
      "Completed 39500 of 50000\n",
      "Completed 40000 of 50000\n",
      "Completed 40500 of 50000\n",
      "Completed 41000 of 50000\n",
      "Completed 41500 of 50000\n",
      "Completed 42000 of 50000\n",
      "Completed 42500 of 50000\n",
      "Completed 43000 of 50000\n",
      "Completed 43500 of 50000\n",
      "Completed 44000 of 50000\n",
      "Completed 44500 of 50000\n",
      "Completed 45000 of 50000\n",
      "Completed 45500 of 50000\n",
      "Completed 46000 of 50000\n",
      "Completed 46500 of 50000\n",
      "Completed 47000 of 50000\n",
      "Completed 47500 of 50000\n",
      "Completed 48000 of 50000\n",
      "Completed 48500 of 50000\n",
      "Completed 49000 of 50000\n",
      "Completed 49500 of 50000\n",
      "Training data images: (50000, 2916)\n",
      "              length: (50000, 5)\n",
      "              digits: (50000, 5, 10)\n",
      "Creating new Validation data from about 100 digits\n",
      "Test & Validation data images: (12000, 2916)\n",
      "                length: (12000, 5)\n",
      "                digits: (12000, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "#Let's build the new training set\n",
    "train_size=50000\n",
    "valid_size=12000\n",
    "\n",
    "import random\n",
    "def createDataset(originalDataSet,dataSize,sizeOfDigitsFromOriginal):\n",
    "    newDataset=np.ndarray([dataSize,imgSize*imgSize])\n",
    "    lengthLabels=np.ndarray([dataSize,5])\n",
    "    digitsLabels = np.zeros([dataSize,5,10])\n",
    "    for i in range(0, dataSize):\n",
    "        numberOfDigits=random.randint(1,5)\n",
    "        digits = np.ndarray([5,28,28])\n",
    "        for j in range(0, 5):\n",
    "            index=random.randint(0,sizeOfDigitsFromOriginal);\n",
    "            randImage=train_dataset[index]\n",
    "            randImage=np.reshape(randImage, [28, 28])\n",
    "            digits[j] = np.copy(randImage)\n",
    "            if j < numberOfDigits:\n",
    "                digitsLabels[i][j][0:10]=train_labels[index]\n",
    "            #    digitsLabels[i][j][0:10]=train_labels[index]\n",
    "            #else:\n",
    "            #    digitsLabels[i][j][10] = 1\n",
    "            \n",
    "        \n",
    "        #print(digitsLabels[i])\n",
    "        variant = getVariant(digits, imgSize)\n",
    "#         plt.imshow(variant, cmap='gray')\n",
    "#         plt.show()\n",
    "        \n",
    "        newDataset[i]=variant.reshape((imgSize*imgSize))\n",
    "        lengthLabels[i]=oneHot(numberOfDigits,5)\n",
    "        #print(lengthLabels[i])\n",
    "        if (i % 500 == 0):\n",
    "            print('Completed %d of %d' % (i, dataSize))\n",
    "    return newDataset, lengthLabels, digitsLabels\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "def maybeLoadData(dataset, size, pickleFile):\n",
    "    import os.path\n",
    "    import pickle\n",
    "    file_path=pickleFile + '.pk'\n",
    "    if(os.path.exists(file_path) is False):\n",
    "        imageData, imageLengths, imageDigits = createDataset(dataset, size, dataset.shape[0]//100)\n",
    "        data = { 'imageData': imageData, 'imageLengths': imageLengths, 'imageDigits': imageDigits}\n",
    "        pickle.dump(data , open( file_path, \"wb\" ))\n",
    "        imageData=imageData.astype(np.float32)\n",
    "        imageLengths=imageLengths.astype(np.float32)\n",
    "        \n",
    "    data = pickle.load( open( file_path, \"rb\" ) );\n",
    "    return data['imageData'], data['imageLengths'], data['imageDigits']\n",
    "\n",
    "print('Creating new Train data from about 2000 digits')\n",
    "newTrainData, newTrainLengths, newTrainDigitLabels = maybeLoadData(train_dataset,train_size, 'synth_train')\n",
    "print(\"Training data images: {}\".format(newTrainData.shape))\n",
    "print(\"              length: {}\".format(newTrainLengths.shape))\n",
    "print(\"              digits: {}\".format(newTrainDigitLabels.shape))\n",
    "\n",
    "\n",
    "print('Creating new Validation data from about 100 digits')\n",
    "newValidationData, newValidationLengths, newValidationDigitLabels = maybeLoadData(valid_dataset,valid_size, 'synth_val')\n",
    "print(\"Test & Validation data images: {}\".format(newValidationData.shape))\n",
    "print(\"                length: {}\".format(newValidationLengths.shape))    \n",
    "print(\"                digits: {}\".format(newValidationDigitLabels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Deep Neural Network Model\n",
    "batch_size = 150\n",
    "image_size=imgSize*imgSize\n",
    "layer1_size = imgSize*imgSize//4\n",
    "layer2_size = 256\n",
    "layer3_size = 32\n",
    "num_labels=5\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(None, image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(None, num_labels))\n",
    "  tf_valid_dataset = tf.constant(newValidationData)\n",
    "  tf_test_dataset = tf.constant(newTestData)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.get_variable('W1', shape=[image_size, layer1_size], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "  biases1 = tf.Variable(tf.zeros([layer1_size]))\n",
    "    \n",
    "  weights2 = tf.get_variable('W2', shape=[layer1_size, layer2_size], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "  biases2 = tf.Variable(tf.zeros([layer2_size]))\n",
    "    \n",
    "  weights3 = tf.get_variable('W3', shape=[layer2_size, layer3_size], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "  biases3 = tf.Variable(tf.zeros([layer3_size]))\n",
    "    \n",
    "  weights4 = tf.get_variable('W4', shape=[layer3_size, num_labels], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "  biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  def model(data):\n",
    "      logits1 = tf.matmul(data, weights1) + biases1\n",
    "      relu1 = tf.nn.relu6(logits1)\n",
    "      logits2 = tf.matmul(relu1, weights2) + biases2\n",
    "      relu2 =tf.nn.relu6(logits2)\n",
    "      logits3 = tf.matmul(relu2, weights3) + biases3\n",
    "      relu3 =tf.nn.relu6(logits3)\n",
    "      logits4 = tf.matmul(relu3, weights4) + biases4\n",
    "      return logits4\n",
    "    \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss1 = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  l2Loss = loss1 + ((tf.nn.l2_loss(weights1)+ tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3) + tf.nn.l2_loss(weights4))/(2*batch_size))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(l2Loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "num_steps = 15001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (newTrainLength.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = newTrainData[offset:(offset + batch_size), :]\n",
    "        batch_labels = newTrainLength[offset:(offset + batch_size), :]\n",
    "\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, l2Loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                valid_prediction.eval(), newValidationLength))\n",
    "    predicted_test=test_prediction.eval();\n",
    "    print('Test accuracy: %.1f%%' % accuracy(predicted_test, newTestLength))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateJointDataSet(size, original_data, original_length, original_digits):\n",
    "    counters = [0,0,0,0,0]\n",
    "    for i in range(0, size):\n",
    "        pixels = original_data[i]\n",
    "        length = np.argmax(original_length[i])+1\n",
    "        for j in range(0,length):\n",
    "            counters[j] = counters[j]+1\n",
    "    \n",
    "    print ('Length of the data for each position: ', counters)\n",
    "    \n",
    "    new_data_p0 = np.ndarray([counters[0], image_size]).astype(np.float32)\n",
    "    new_labels_p0 = np.ndarray([counters[0], 10]).astype(np.float32)\n",
    "    new_data_p1 = np.ndarray([counters[1], image_size]).astype(np.float32)\n",
    "    new_labels_p1 = np.ndarray([counters[1], 10]).astype(np.float32)\n",
    "    new_data_p2 = np.ndarray([counters[2], image_size]).astype(np.float32)\n",
    "    new_labels_p2 = np.ndarray([counters[2], 10]).astype(np.float32)\n",
    "    new_data_p3 = np.ndarray([counters[3], image_size]).astype(np.float32)\n",
    "    new_labels_p3 = np.ndarray([counters[3], 10]).astype(np.float32)\n",
    "    new_data_p4 = np.ndarray([counters[4], image_size]).astype(np.float32)\n",
    "    new_labels_p4 = np.ndarray([counters[4], 10]).astype(np.float32)\n",
    "    \n",
    "    counters=[0,0,0,0,0]\n",
    "    new_map=np.full([size,5],-1)\n",
    "    for i in range(0, size):\n",
    "        pixels = original_data[i]\n",
    "        length = np.argmax(original_length[i])+1\n",
    "        for j in range(0, length):\n",
    "            digit=original_digits[i][j]\n",
    "            if j==0:\n",
    "                new_data_p0[counters[j]]=pixels\n",
    "                new_labels_p0[counters[j]]=digit\n",
    "            if j==1:\n",
    "                new_data_p1[counters[j]]=pixels\n",
    "                new_labels_p1[counters[j]]=digit\n",
    "            if j==2:\n",
    "                new_data_p2[counters[j]]=pixels\n",
    "                new_labels_p2[counters[j]]=digit\n",
    "            if j==3:\n",
    "                new_data_p3[counters[j]]=pixels\n",
    "                new_labels_p3[counters[j]]=digit\n",
    "            if j==4:\n",
    "                new_data_p4[counters[j]]=pixels\n",
    "                new_labels_p4[counters[j]]=digit\n",
    "            new_map[i][j] = int(counters[j])\n",
    "            counters[j] = int(counters[j])+1\n",
    "        if (i % 500 == 0):\n",
    "            print('Completed %d of %d' % (i, size))\n",
    "    return new_data_p0,new_labels_p0,new_data_p1,new_labels_p1,new_data_p2,new_labels_p2,new_data_p3,new_labels_p3,new_data_p4,new_labels_p4,new_map\n",
    "\n",
    "joined_train_data_size = newTrainData.shape[0]\n",
    "joined_validation_data_size = newValidationData.shape[0]\n",
    "joined_test_data_size=newTestData.shape[0]\n",
    "print('Creating joint training data from ground truth')\n",
    "jointTrainData0, jointTrainLabels0, jointTrainData1, jointTrainLabels1, jointTrainData2, jointTrainLabels2, jointTrainData3, jointTrainLabels3, jointTrainData4, jointTrainLabels4, jointTrainDataMap = generateJointDataSet(joined_train_data_size, newTrainData, newTrainLength,newTrainDigitLabels)\n",
    "print('Creating joint validation data from ground truth')\n",
    "jointValidationData0, jointValidationLabels0, jointValidationData1, jointValidationLabels1, jointValidationData2, jointValidationLabels2, jointValidationData3, jointValidationLabels3, jointValidationData4, jointValidationLabels4, jointValidationDataMap = generateJointDataSet(joined_validation_data_size, newValidationData, newValidationLength,newValidationDigitLabels)\n",
    "print('Creating joint test data from prediction')\n",
    "jointTestData0, jointTestLabels0, jointTestData1, jointTestLabels1, jointTestData2, jointTestLabels2, jointTestData3, jointTestLabels3, jointTestData4, jointTestLabels4, jointTestDataMap = generateJointDataSet(joined_test_data_size, newTestData, predicted_test,newTestDigitLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learnAndPredict(num_steps,jointTrainData,jointTrainLabels,jointValidationData,jointValidationLabels,jointTestData,jointTestLabels):\n",
    "    batch_size = 250\n",
    "    input_size=imgSize*imgSize\n",
    "    layer1_size = input_size//4\n",
    "    layer2_size = 512\n",
    "    layer3_size = 256\n",
    "    \n",
    "   \n",
    "    num_digits = 10\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                        shape=(None, input_size))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(None, num_digits))\n",
    "      tf_valid_dataset = tf.constant(jointValidationData)\n",
    "      tf_test_dataset = tf.constant(jointTestData)\n",
    "\n",
    "      # Variables.\n",
    "      weights1 = tf.get_variable('W1', shape=[input_size, layer1_size], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "      biases1 = tf.Variable(tf.zeros([layer1_size]))\n",
    "\n",
    "      weights2 = tf.get_variable('W2', shape=[layer1_size, layer2_size], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "      biases2 = tf.Variable(tf.zeros([layer2_size]))\n",
    "\n",
    "      weights3 = tf.get_variable('W3', shape=[layer2_size, layer3_size], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "      biases3 = tf.Variable(tf.zeros([layer3_size]))\n",
    "\n",
    "      weights4 = tf.get_variable('W4', shape=[layer3_size, num_digits], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "      biases4 = tf.Variable(tf.zeros([num_digits]))\n",
    "\n",
    "     \n",
    "\n",
    "      def model(data):\n",
    "          logits1 = tf.matmul(data, weights1) + biases1\n",
    "          relu1 = tf.nn.relu6(logits1)\n",
    "          logits2 = tf.matmul(relu1, weights2) + biases2\n",
    "          relu2 =tf.nn.relu6(logits2)\n",
    "          logits3 = tf.matmul(relu2, weights3) + biases3\n",
    "          relu3 =tf.nn.relu6(logits3)\n",
    "          logits4 = tf.matmul(relu3, weights4) + biases4\n",
    "          return logits4\n",
    "\n",
    "      # Training computation.\n",
    "      logits = model(tf_train_dataset)\n",
    "      loss1 = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "      l2Loss = loss1 + ((tf.nn.l2_loss(weights1)+ tf.nn.l2_loss(weights2) + tf.nn.l2_loss(weights3) + tf.nn.l2_loss(weights4) )/(2*batch_size))\n",
    "\n",
    "      # Optimizer.\n",
    "      optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(l2Loss)\n",
    "\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(logits)\n",
    "      valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "      test_prediction = tf.nn.softmax(model(tf_test_dataset))\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (jointTrainLabels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = jointTrainData[offset:(offset + batch_size), :]\n",
    "            batch_labels = jointTrainLabels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run(\n",
    "              [optimizer, l2Loss, train_prediction], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "                print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                    valid_prediction.eval(), jointValidationLabels))\n",
    "        predicted_digits=test_prediction.eval();\n",
    "        print('Test accuracy: %.1f%%' % accuracy(predicted_digits, jointTestLabels))\n",
    "    return predicted_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictedDigits4=learnAndPredict(20001,jointTrainData4,jointTrainLabels4,jointValidationData4, jointValidationLabels4,jointTestData4,jointTestLabels4)\n",
    "predictedDigits3=learnAndPredict(20001,jointTrainData3,jointTrainLabels3,jointValidationData3, jointValidationLabels3,jointTestData3,jointTestLabels3)\n",
    "predictedDigits2=learnAndPredict(20001,jointTrainData2,jointTrainLabels2,jointValidationData2, jointValidationLabels2,jointTestData2,jointTestLabels2)\n",
    "predictedDigits1=learnAndPredict(20001,jointTrainData1,jointTrainLabels1,jointValidationData1, jointValidationLabels1,jointTestData1,jointTestLabels1)\n",
    "predictedDigits0=learnAndPredict(20001,jointTrainData0,jointTrainLabels0,jointValidationData0, jointValidationLabels0,jointTestData0,jointTestLabels0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "I created the dataset by using notMNIST dataset. \n",
    "1. First we create 1-5 digit numbers using individual digits from the notMNIST dataset. \n",
    "2. We then resize them to the 54x54 size as suggested.\n",
    "3. We create and store the .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define some useful Functions\n",
    "import h5py\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "\n",
    "#CONSTANTS\n",
    "imgSize = 54\n",
    "\n",
    "def get_box_data(index, hdf5_data):\n",
    "    \"\"\"\n",
    "    get `left, top, width, height` of each picture\n",
    "    :param index:\n",
    "    :param hdf5_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_data = dict()\n",
    "    meta_data['height'] = []\n",
    "    meta_data['label'] = []\n",
    "    meta_data['left'] = []\n",
    "    meta_data['top'] = []\n",
    "    meta_data['width'] = []\n",
    "\n",
    "    def print_attrs(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(int(hdf5_data[obj[k][0]][0][0]))\n",
    "        meta_data[name] = vals\n",
    "\n",
    "    box = hdf5_data['/digitStruct/bbox'][index]\n",
    "    hdf5_data[box[0]].visititems(print_attrs)\n",
    "    return meta_data\n",
    "\n",
    "def get_name(index, hdf5_data):\n",
    "    name = hdf5_data['/digitStruct/name']\n",
    "    return ''.join([chr(v[0]) for v in hdf5_data[name[index][0]].value])\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def oneHot(num, length):\n",
    "    arr = np.zeros(length)\n",
    "    arr[num-1]=1\n",
    "    return arr\n",
    "def maybeLoadData(folder, variations):\n",
    "    import os.path\n",
    "    import pickle\n",
    "    file_path=folder + '.pk'\n",
    "    if(os.path.exists(file_path) is False):\n",
    "        imageData, imageLengths, imageDigits = loadData(folder, variations)\n",
    "        data = { 'imageData': imageData, 'imageLengths': imageLengths, 'imageDigits': imageDigits}\n",
    "        out = open( file_path, \"wb\" )\n",
    "        pickle.dump(data , out )\n",
    "        out.close()\n",
    "    data = pickle.load( open( file_path, \"rb\" ) );\n",
    "    return data['imageData'], data['imageLengths'], data['imageDigits']\n",
    "    \n",
    "def loadData(folder, variations):\n",
    "    #First load the data using h5py\n",
    "    f = h5py.File(folder + '/' + 'digitStruct.mat')\n",
    "    #Get the number of images to iterate through them\n",
    "    length = len(f['/digitStruct/name'])\n",
    "    \n",
    "    if(length>100000):\n",
    "        length = 100000;   #MaxLength\n",
    "    \n",
    "    imageData = np.zeros([length, imgSize,imgSize,1]).astype(np.float32)\n",
    "    imageLengths = np.zeros([length, 5]).astype(np.int)\n",
    "    imageDigits = np.zeros([length,5,10]).astype(np.int)\n",
    "    \n",
    "    #Iterate through the images\n",
    "    for i in range(0,length):\n",
    "        if(i%500==0): #In case of error, comment this line\n",
    "            print(\"Loaded {} out of {}\".format(i,length)) \n",
    "        #Read the image\n",
    "        imageFile = folder + '/' + get_name(i,f)\n",
    "        img = cv2.imread(imageFile)\n",
    "\n",
    "        #Read the box data & get the bounding box for all characters (using first and last digit)\n",
    "        boxData=get_box_data(i, f)\n",
    "        \n",
    "        firstTop = int(boxData['top'][0])\n",
    "        firstLeft = int(boxData['left'][0])\n",
    "        firstRight = int(boxData['left'][0]) + int(boxData['width'][0]) \n",
    "        firstBottom = int(boxData['top'][0]) + int(boxData['height'][0])\n",
    "        \n",
    "        l = len(boxData['top'])\n",
    "        lastTop = int(boxData['top'][l-1])\n",
    "        lastLeft = int(boxData['left'][l-1])\n",
    "        lastRight = int(boxData['left'][l-1]) + int(boxData['width'][l-1]) \n",
    "        lastBottom = int(boxData['top'][l-1]) + int(boxData['height'][l-1])\n",
    "        \n",
    "        top = min(firstTop, lastTop)\n",
    "        left = min(firstLeft, lastLeft)\n",
    "        right = max(firstRight, lastRight)\n",
    "        bottom = max(firstBottom, lastBottom)\n",
    "        \n",
    "        height = bottom-top\n",
    "        width = right-left\n",
    "        vertMiddle = (bottom+top)//2\n",
    "        horCenter = (left+right)//2\n",
    "        \n",
    "        if(variations==True):\n",
    "            top = vertMiddle - ((1.3*height)//2)\n",
    "            bottom = vertMiddle + ((1.3*height)//2)\n",
    "            left = horCenter - ((1.3*width)//2)\n",
    "            right = horCenter + ((1.3*width)//2)\n",
    "        \n",
    "        top = max(top, 0)\n",
    "        left = max(left, 0)\n",
    "        right = min(right, img.shape[1])\n",
    "        bottom = min(bottom, img.shape[0])\n",
    "         \n",
    "            #One image has incorrect label length of  6 \n",
    "#         if(len(boxData['label'])>5):\n",
    "#             cv2.imshow('image',img)\n",
    "#             cv2.waitKey(0)\n",
    "\n",
    "        #Check to see the bounding box\n",
    "        #cv2.rectangle(img,(left,top),(right, bottom),(0,255,0),3)\n",
    "\n",
    "        #Extract only the RoI for faster pre-processing\n",
    "        img = img[top:bottom, left:right]\n",
    "        \n",
    "        #Convert to gray scale if in color\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #Histogram correction\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(6,6))\n",
    "        img = clahe.apply(img)\n",
    "        \n",
    "        #Length of digits \n",
    "        numberOfDigits = len(boxData['label'])\n",
    "        \n",
    "        #Save the original for comparison if needed\n",
    "        #orig = cv2.resize(img,(imgSize, imgSize), interpolation = cv2.INTER_LANCZOS4)\n",
    "                \n",
    "        #Enhance edges\n",
    "#         edge_enhancement_kernel = np.array([[-1,-1,-1,-1,-1],\n",
    "#                              [-1,2,2,2,-1],\n",
    "#                              [-1,2,8,2,-1],\n",
    "#                              [-1,2,2,2,-1],\n",
    "#                              [-1,-1,-1,-1,-1]]) / 8.0\n",
    "        \n",
    "            \n",
    "#         img = cv2.filter2D(img, -1, edge_enhancement_kernel)\n",
    "#         img = cv2.filter2D(img, -1, edge_enhancement_kernel)\n",
    "        \n",
    "        #Resize the image to 64x64\n",
    "        if(variations==True):\n",
    "            img = cv2.resize(img,(64, 64), interpolation = cv2.INTER_LANCZOS4)\n",
    "            leftStart=random.randint(0,9)\n",
    "            topStart=random.randint(0,9)    \n",
    "            img = img[topStart:(topStart+imgSize), leftStart:(leftStart+imgSize)]\n",
    "        else: \n",
    "            img = cv2.resize(img,(imgSize, imgSize), interpolation = cv2.INTER_LANCZOS4)\n",
    "            \n",
    "        #Copy the data\n",
    "        oneImageData = np.resize(img, (imgSize,imgSize,1)).astype(np.float32)\n",
    "        \n",
    "        oneImageData=oneImageData/255.0\n",
    "        oneImageData=oneImageData-0.5\n",
    "        \n",
    "        imageData[i] = oneImageData\n",
    "        first=0\n",
    "        if(numberOfDigits>5):\n",
    "            numberOfDigits=5\n",
    "            print(boxData['label'])\n",
    "            first=1\n",
    "            \n",
    "        imageLengths[i] = oneHot(numberOfDigits,5)\n",
    "        \n",
    "        for k in range(0,5):\n",
    "            if(k<numberOfDigits):\n",
    "                imageDigits[i,k,:]=oneHot(int(boxData['label'][int(k+first)]),10)\n",
    "            #else:\n",
    "            #    imageDigits[i,k,10]=1\n",
    "        \n",
    "            \n",
    "        #Show the original image\n",
    "        #cv2.imshow('image',orig)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "        #Show the processed image\n",
    "        #cv2.imshow('image',img)\n",
    "        #cv2.waitKey(0)\n",
    "        \n",
    "    shuffledIndexes  = np.arange(length)\n",
    "    np.random.shuffle(shuffledIndexes)\n",
    "    \n",
    "    imageData = imageData[shuffledIndexes,:]\n",
    "    imageLengths = imageLengths[shuffledIndexes,:]\n",
    "    imageDigits = imageDigits[shuffledIndexes,:,:]\n",
    "    return imageData,imageLengths, imageDigits\n",
    "        \n",
    "print(\"Loading training data\")    \n",
    "trainImageData, trainImageLengths,trainImageDigits = maybeLoadData('train', True)\n",
    "print(\"Training data images: {}\".format(trainImageData.shape))\n",
    "print(\"              length: {}\".format(trainImageLengths.shape))\n",
    "print(\"              digits: {}\".format(trainImageDigits.shape))\n",
    "# extraImageData, extraImageLengths,extraImageDigits = maybeLoadData('extra', True)\n",
    "# print(\"Extra data    images: {}\".format(extraImageData.shape))\n",
    "# print(\"              length: {}\".format(extraImageLengths.shape))\n",
    "# print(\"              digits: {}\".format(extraImageDigits.shape))\n",
    "\n",
    "# trainImageData  = np.concatenate((trainImageData, extraImageData))\n",
    "# trainImageLengths  = np.concatenate((trainImageLengths, extraImageLengths))\n",
    "# trainImageDigits  = np.concatenate((trainImageDigits, extraImageDigits))\n",
    "# print(\"Training data images: {}\".format(trainImageData.shape))\n",
    "# print(\"              length: {}\".format(trainImageLengths.shape))\n",
    "# print(\"              digits: {}\".format(trainImageDigits.shape))\n",
    "\n",
    "\n",
    "print(\"Loading test & validation data\")    \n",
    "folderImageData, folderImageLengths,folderImageDigits = maybeLoadData('test', False)\n",
    "print(\"Folder test data images: {}\".format(folderImageData.shape))\n",
    "print(\"          length: {}\".format(folderImageLengths.shape))\n",
    "print(\"          digits: {}\".format(folderImageDigits.shape))\n",
    "\n",
    "half = len(folderImageData)//2\n",
    "validationImageData = folderImageData[0:half,:]\n",
    "validationImageLengths = folderImageLengths[0:half,:]\n",
    "validationImageDigits= folderImageDigits[0:half,:,:]\n",
    "print(\"Validation data images: {}\".format(validationImageData.shape))\n",
    "print(\"                length: {}\".format(validationImageLengths.shape))    \n",
    "print(\"                digits: {}\".format(validationImageDigits.shape))\n",
    "\n",
    "testImageData = folderImageData[half:,:]\n",
    "testImageLengths = folderImageLengths[half:,:]\n",
    "testImageDigits= folderImageDigits[half:,:,:]\n",
    "print(\"Test data images: {}\".format(testImageData.shape))\n",
    "print(\"          length: {}\".format(testImageLengths.shape))  \n",
    "print(\"          digits: {}\".format(testImageDigits.shape))\n",
    "\n",
    "print(\"Data loaded.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Confirm Data\n",
    "d=65\n",
    "plt.imshow(testImageData[d].reshape((imgSize,imgSize)), cmap='gray')\n",
    "plt.show()\n",
    "print(testImageLengths[d])\n",
    "print(testImageDigits[d])\n",
    "\n",
    "testDigit0  = testImageDigits[:,0,:]\n",
    "testDigit1  = testImageDigits[:,1,:]\n",
    "testDigit2  = testImageDigits[:,2,:]\n",
    "testDigit3  = testImageDigits[:,3,:]\n",
    "testDigit4  = testImageDigits[:,4,:]\n",
    "\n",
    "print(testDigit0[d])\n",
    "print(testDigit1[d])\n",
    "print(testDigit2[d])\n",
    "print(testDigit3[d])\n",
    "print(testDigit4[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Reshape, MaxPooling2D, Input, Flatten, merge, Convolution2D, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "%matplotlib inline\n",
    "\n",
    "batch_size = 50\n",
    "inputSize=imgSize*imgSize\n",
    "num_labels=5\n",
    "epochs=100\n",
    "\n",
    "x = Input(batch_shape=(None, imgSize, imgSize,1))\n",
    "# conv = Convolution2D(48, 5, 5, border_mode='same', W_regularizer=l2(0.01))(x)\n",
    "# conv = BatchNormalization()(conv)\n",
    "# conv = Activation('relu')(conv)\n",
    "# conv = MaxPooling2D(pool_size = (2,2), strides=(2,2))(conv)\n",
    "# conv = Dropout(0.4)(conv)\n",
    "\n",
    "dense = Flatten()(x)\n",
    "dense = Dense(inputSize*5, W_regularizer=l2(0.01))(dense)\n",
    "dense = Activation('relu')(dense)\n",
    "\n",
    "outL = Dense(5, W_regularizer=l2(0.01))(dense)\n",
    "outL = Activation('softmax', name=\"Length\")(outL)\n",
    "outD0 = Dense(10, W_regularizer=l2(0.01))(dense)\n",
    "outD0 = Activation('sigmoid', name=\"Digit0\")(outD0)\n",
    "outD1 = Dense(10, W_regularizer=l2(0.01))(dense)\n",
    "outD1 = Activation('sigmoid', name=\"Digit1\")(outD1)\n",
    "outD2 = Dense(10, W_regularizer=l2(0.01))(dense)\n",
    "outD2 = Activation('sigmoid', name=\"Digit2\")(outD2)\n",
    "outD3 = Dense(10, W_regularizer=l2(0.01))(dense)\n",
    "outD3 = Activation('sigmoid', name=\"Digit3\")(outD3)\n",
    "outD4 = Dense(10, W_regularizer=l2(0.01))(dense)\n",
    "outD4 = Activation('sigmoid', name=\"Digit4\")(outD4)\n",
    "\n",
    "model = Model(input=x, output=[outL, outD0, outD1, outD2, outD3, outD4])\n",
    "\n",
    "\n",
    "\n",
    "# from keras.utils.visualize_util import plot\n",
    "# plot(model, to_file='model.png')\n",
    "\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "trainReshaped = trainImageData.reshape((-1,imgSize,imgSize,1))\n",
    "trainDigit0  = trainImageDigits[:,0,:]\n",
    "trainDigit1  = trainImageDigits[:,1,:]\n",
    "trainDigit2  = trainImageDigits[:,2,:]\n",
    "trainDigit3  = trainImageDigits[:,3,:]\n",
    "trainDigit4  = trainImageDigits[:,4,:]\n",
    "\n",
    "validationReshaped = validationImageData.reshape((-1,imgSize,imgSize,1))\n",
    "validationDigit0  = validationImageDigits[:,0,:]\n",
    "validationDigit1  = validationImageDigits[:,1,:]\n",
    "validationDigit2  = validationImageDigits[:,2,:]\n",
    "validationDigit3  = validationImageDigits[:,3,:]\n",
    "validationDigit4  = validationImageDigits[:,4,:]\n",
    "model.fit(trainReshaped, [trainImageLengths, trainDigit0, trainDigit1, trainDigit2, trainDigit3, trainDigit4], nb_epoch=epochs, batch_size=batch_size, validation_data=(validationReshaped,[validationImageLengths,validationDigit0,validationDigit1,validationDigit2,validationDigit3,validationDigit4]))\n",
    "model.save('actualModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
